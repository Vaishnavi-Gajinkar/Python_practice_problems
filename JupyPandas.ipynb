{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ca0883e-a2e0-4615-ab42-0664fe5a9fa6",
   "metadata": {},
   "source": [
    "    CREATION OF DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f935df5-943f-4819-934d-a8da9945fd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Age  Salary\n",
      "0   John   25   30000\n",
      "1  Peter   28   40000\n",
      "2   Lisa   31   50000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "emp = {\"Name\":[\"John\",\"Peter\",\"Lisa\"],\n",
    "        \"Age\":[25,28,31],\n",
    "       \"Salary\":[30000,40000,50000]\n",
    "}\n",
    "print(pd.DataFrame(emp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ff99ba6-f546-4d9c-bb4f-d5a054032724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id     name      created time private/public  post count Verified status\n",
      "0     1   Kenton  16-02-2017 18.22            yes          11              no\n",
      "1     2    Andre  02-04-2017 17.11             no           7              no\n",
      "2     3   Harley  21-02-2017 11.12             no           2              no\n",
      "3     4    Arely   13-08-2016 1.28            yes           1              no\n",
      "4     5    Aniya   07-12-2016 1.04            yes           3              no\n",
      "..  ...      ...               ...            ...         ...             ...\n",
      "95   96   Keenan  28-08-2016 14.57            yes         687              no\n",
      "96   97    Tomas  11-02-2017 11.38            yes          92              no\n",
      "97   98    Imani  31-01-2017 22.59             no         123              no\n",
      "98   99     Alek   10-12-2016 7.43             no         232              no\n",
      "99  100  Javonte  27-03-2017 22.06            yes          32             yes\n",
      "\n",
      "[100 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/Users/vaish/Downloads/DataSets/Insta_ds/users.csv\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f08f51f-4f22-42b8-ac21-3fcf6afde699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id     name      created time private/public  post count Verified status\n",
      "0   1   Kenton  16-02-2017 18.22            yes          11              no\n",
      "1   2    Andre  02-04-2017 17.11             no           7              no\n",
      "2   3   Harley  21-02-2017 11.12             no           2              no\n",
      "3   4    Arely   13-08-2016 1.28            yes           1              no\n",
      "4   5    Aniya   07-12-2016 1.04            yes           3              no\n",
      "5   6   Travon  30-04-2017 13.26             no          14              no\n",
      "6   7   Kasand   12-12-2016 6.50             no         244              no\n",
      "7   8  Tabitha   20-08-2016 2.19            yes          12              no\n",
      "8   9    Gus93  24-06-2016 19.36            yes          45              no\n",
      "9  10  Presley  07-08-2016 16.25             no         370              no\n",
      "     id     name      created time private/public  post count Verified status\n",
      "90   91   Bethan  03-06-2016 23.31             no          79              no\n",
      "91   92  Frederi  06-07-2016 21.56            yes           2              no\n",
      "92   93   Willie   15-02-2017 1.40            yes           1              no\n",
      "93   94    Damon  31-10-2016 14.44             no           0             yes\n",
      "94   95   Nicole  09-05-2016 17.30             no           9              no\n",
      "95   96   Keenan  28-08-2016 14.57            yes         687              no\n",
      "96   97    Tomas  11-02-2017 11.38            yes          92              no\n",
      "97   98    Imani  31-01-2017 22.59             no         123              no\n",
      "98   99     Alek   10-12-2016 7.43             no         232              no\n",
      "99  100  Javonte  27-03-2017 22.06            yes          32             yes\n"
     ]
    }
   ],
   "source": [
    "# to view top/bottom x rows of data\n",
    "print(data.head(10))\n",
    "print(data.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13a210c3-2dd1-4d30-9f88-3f7772675ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   id               100 non-null    int64 \n",
      " 1   name             100 non-null    object\n",
      " 2   created time     100 non-null    object\n",
      " 3   private/public   100 non-null    object\n",
      " 4   post count       100 non-null    int64 \n",
      " 5   Verified status  100 non-null    object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 4.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# to get info about datatypes of different cols of data\n",
    "\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec94b7d2-ea3b-4dfc-a7ec-3a1ebcdb554e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>post count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50.500000</td>\n",
       "      <td>215.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.011492</td>\n",
       "      <td>534.756995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.750000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.500000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>75.250000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>2400.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id   post count\n",
       "count  100.000000   100.000000\n",
       "mean    50.500000   215.370000\n",
       "std     29.011492   534.756995\n",
       "min      1.000000     0.000000\n",
       "25%     25.750000     2.000000\n",
       "50%     50.500000    12.000000\n",
       "75%     75.250000    78.000000\n",
       "max    100.000000  2400.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to summarize numerical columns of data\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8b4ad1c-22a0-4207-94b6-4fff154c123f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=100, step=1) \n",
      "\n",
      "Index(['id', 'name', 'created time', 'private/public', 'post count',\n",
      "       'Verified status'],\n",
      "      dtype='object') \n",
      "\n",
      "[[1 'Kenton' '16-02-2017 18.22' 'yes' 11 'no']\n",
      " [2 'Andre' '02-04-2017 17.11' 'no' 7 'no']\n",
      " [3 'Harley' '21-02-2017 11.12' 'no' 2 'no']\n",
      " [4 'Arely' '13-08-2016 1.28' 'yes' 1 'no']\n",
      " [5 'Aniya' '07-12-2016 1.04' 'yes' 3 'no']\n",
      " [6 'Travon' '30-04-2017 13.26' 'no' 14 'no']\n",
      " [7 'Kasand' '12-12-2016 6.50' 'no' 244 'no']\n",
      " [8 'Tabitha' '20-08-2016 2.19' 'yes' 12 'no']\n",
      " [9 'Gus93' '24-06-2016 19.36' 'yes' 45 'no']\n",
      " [10 'Presley' '07-08-2016 16.25' 'no' 370 'no']\n",
      " [11 'Justina' '04-05-2017 16.32' 'no' 1293 'no']\n",
      " [12 'Dereck' '19-01-2017 1.34' 'yes' 11 'no']\n",
      " [13 'Alexand' '29-03-2017 17.09' 'yes' 7 'no']\n",
      " [14 'Jaclyn' '06-02-2017 23.29' 'no' 2 'no']\n",
      " [15 'Billy52' '05-10-2016 14.10' 'no' 1 'no']\n",
      " [16 'Annali' '02-08-2016 21.32' 'yes' 3 'no']\n",
      " [17 'Norbert' '06-02-2017 22.05' 'yes' 14 'yes']\n",
      " [18 'Odessa' '21-10-2016 18.16' 'no' 244 'no']\n",
      " [19 'Hailee' '29-04-2017 18.53' 'no' 12 'no']\n",
      " [20 'Delpha' '31-08-2016 2.42' 'yes' 45 'no']\n",
      " [21 'Rocio33' '23-01-2017 11.51' 'yes' 370 'no']\n",
      " [22 'Kennet' '27-12-2016 9.48' 'no' 1293 'no']\n",
      " [23 'Eveline' '23-01-2017 23.14' 'no' 2400 'no']\n",
      " [24 'Maxwell' '18-04-2017 2.32' 'yes' 12 'no']\n",
      " [25 'Tierra' '03-10-2016 12.49' 'yes' 59 'no']\n",
      " [26 'Josianne' '07-06-2016 12.47' 'no' 56 'no']\n",
      " [27 'Darwin' '18-03-2017 3.10' 'no' 78 'yes']\n",
      " [28 'Dario77' '18-08-2016 7.15' 'yes' 2 'yes']\n",
      " [29 'Jaime53' '11-09-2016 18.51' 'yes' 1 'no']\n",
      " [30 'Kaley9' '23-09-2016 21.24' 'no' 0 'no']\n",
      " [31 'Aiyana' '29-09-2016 20.28' 'no' 12 'no']\n",
      " [32 'Irwin' '26-08-2016 19.36' 'yes' 45 'no']\n",
      " [33 'Yvette' '14-11-2016 12.32' 'yes' 370 'no']\n",
      " [34 'Pearl7' '08-07-2016 21.42' 'no' 1293 'no']\n",
      " [35 'Lennie' '30-03-2017 3.25' 'no' 2400 'no']\n",
      " [36 'Ollie' '04-08-2016 15.42' 'yes' 12 'no']\n",
      " [37 'Yazmin' '27-07-2016 0.56' 'yes' 59 'no']\n",
      " [38 'Jordyn' '14-05-2016 7.56' 'no' 56 'no']\n",
      " [39 'Kelsi26' '08-06-2016 17.48' 'no' 78 'no']\n",
      " [40 'Rafael' '19-05-2016 9.51' 'yes' 2 'no']\n",
      " [41 'Mcken' '17-07-2016 17.25' 'yes' 1 'no']\n",
      " [42 'Maya' '11-12-2016 18.04' 'no' 0 'no']\n",
      " [43 'Janet' '06-10-2016 7.57' 'no' 11 'yes']\n",
      " [44 'Seth4' '07-07-2016 11.40' 'yes' 7 'no']\n",
      " [45 'David' '05-02-2017 21.23' 'yes' 2 'no']\n",
      " [46 'Malinda' '09-07-2016 21.37' 'no' 1 'no']\n",
      " [47 'Harrison' '02-09-2016 3.48' 'no' 3 'no']\n",
      " [48 'Granville' '26-06-2016 3.10' 'yes' 14 'no']\n",
      " [49 'Morgan' '30-10-2016 12.42' 'yes' 244 'no']\n",
      " [50 'Gerard' '23-08-2016 19.47' 'no' 12 'no']\n",
      " [51 'Mariano' '17-04-2017 14.14' 'no' 45 'no']\n",
      " [52 'Zack' '01-01-2017 5.58' 'yes' 370 'no']\n",
      " [53 'Linnea' '07-02-2017 7.49' 'yes' 1293 'no']\n",
      " [54 'Duane' '21-12-2016 4.43' 'no' 11 'no']\n",
      " [55 'Meggie' '04-04-2017 12.17' 'no' 7 'no']\n",
      " [56 'Peter' '22-08-2016 18.05' 'yes' 2 'no']\n",
      " [57 'Julien' '02-02-2017 23.12' 'yes' 1 'no']\n",
      " [58 'Aurelie' '31-05-2016 6.20' 'no' 3 'no']\n",
      " [59 'Cesar' '18-10-2016 16.42' 'no' 14 'no']\n",
      " [60 'Sam52' '30-03-2017 22.03' 'yes' 244 'no']\n",
      " [61 'Jayson' '14-10-2016 19.10' 'yes' 12 'no']\n",
      " [62 'Ressie' '20-12-2016 15.09' 'no' 45 'no']\n",
      " [63 'Elenor88' '08-05-2016 1.30' 'no' 370 'no']\n",
      " [64 'Florence' '06-10-2016 23.08' 'yes' 1293 'yes']\n",
      " [65 'Adelle96' '01-10-2016 0.37' 'yes' 2400 'no']\n",
      " [66 'Mike' '01-07-2016 17.36' 'no' 12 'no']\n",
      " [67 'Emilio' '06-05-2016 13.04' 'no' 59 'no']\n",
      " [68 'Franco' '13-11-2016 20.09' 'yes' 56 'no']\n",
      " [69 'Karley' '24-06-2016 23.38' 'yes' 78 'no']\n",
      " [70 'Erick5' '05-04-2017 23.44' 'no' 2 'no']\n",
      " [71 'Nia_Ha' '14-05-2016 15.38' 'no' 1 'no']\n",
      " [72 'Kathryn' '11-10-2016 9.01' 'yes' 12 'no']\n",
      " [73 'Jaylan' '10-06-2016 23.58' 'yes' 3 'no']\n",
      " [74 'Hulda' '25-01-2017 17.17' 'no' 1 'no']\n",
      " [75 'Leslie' '21-09-2016 5.14' 'no' 3 'no']\n",
      " [76 'Janelle' '21-07-2016 9.26' 'yes' 79 'no']\n",
      " [77 'Donald' '07-01-2017 10.05' 'yes' 2 'no']\n",
      " [78 'Colten' '10-10-2016 2.38' 'no' 1 'no']\n",
      " [79 'Katarina' '03-11-2016 13.14' 'no' 0 'no']\n",
      " [80 'djkrhf' '06-05-2016 0.14' 'yes' 2400 'no']\n",
      " [81 'Esther' '14-01-2017 17.02' 'yes' 12 'no']\n",
      " [82 'Aracely' '25-07-2016 18.49' 'no' 59 'no']\n",
      " [83 'Barthol' '06-11-2016 2.31' 'no' 56 'no']\n",
      " [84 'Alysa22' '01-01-2017 17.44' 'yes' 78 'no']\n",
      " [85 'Milford' '30-04-2017 7.50' 'yes' 2 'no']\n",
      " [86 'Delfina' '21-03-2017 12.02' 'no' 1 'no']\n",
      " [87 'Rick29' '24-02-2017 11.25' 'no' 12 'no']\n",
      " [88 'Clint27' '02-06-2016 21.40' 'yes' 3 'yes']\n",
      " [89 'Jessyca' '14-09-2016 23.47' 'yes' 1 'no']\n",
      " [90 'Esmera' '03-03-2017 11.52' 'no' 3 'no']\n",
      " [91 'Bethan' '03-06-2016 23.31' 'no' 79 'no']\n",
      " [92 'Frederi' '06-07-2016 21.56' 'yes' 2 'no']\n",
      " [93 'Willie' '15-02-2017 1.40' 'yes' 1 'no']\n",
      " [94 'Damon' '31-10-2016 14.44' 'no' 0 'yes']\n",
      " [95 'Nicole' '09-05-2016 17.30' 'no' 9 'no']\n",
      " [96 'Keenan' '28-08-2016 14.57' 'yes' 687 'no']\n",
      " [97 'Tomas' '11-02-2017 11.38' 'yes' 92 'no']\n",
      " [98 'Imani' '31-01-2017 22.59' 'no' 123 'no']\n",
      " [99 'Alek' '10-12-2016 7.43' 'no' 232 'no']\n",
      " [100 'Javonte' '27-03-2017 22.06' 'yes' 32 'yes']]\n"
     ]
    }
   ],
   "source": [
    "print(data.index,\"\\n\")\n",
    "print(data.columns,\"\\n\")\n",
    "print(data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0cd7933-a93c-4327-9fac-81a8a64e81e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Prod Id Product Name  Prod Cat Id Prod Cat Name  Prod Price\n",
      "0         191      Nike Me          9.0    Cardio Equ   99.989998\n",
      "1         627      Under A         29.0    Shop By Sp   39.990002\n",
      "2         917      Glove I         41.0      Trade-In         NaN\n",
      "3         828      Bridges         37.0    Electronic   31.990000\n",
      "4         191      Nike Me          9.0    Cardio Equ   99.989998\n",
      "...       ...          ...          ...           ...         ...\n",
      "1264      135      Nike Dr          7.0        Hockey   22.000000\n",
      "1265      135      Nike Dr          7.0        Hockey   22.000000\n",
      "1266      135      Nike Dr          7.0        Hockey   22.000000\n",
      "1267      135      Nike Dr          7.0        Hockey   22.000000\n",
      "1268      135      Nike Dr          7.0           NaN   22.000000\n",
      "\n",
      "[1269 rows x 5 columns]\n",
      "      Prod Id  Product Name  Prod Cat Id  Prod Cat Name  Prod Price\n",
      "0       False         False        False          False       False\n",
      "1       False         False        False          False       False\n",
      "2       False         False        False          False        True\n",
      "3       False         False        False          False       False\n",
      "4       False         False        False          False       False\n",
      "...       ...           ...          ...            ...         ...\n",
      "1264    False         False        False          False       False\n",
      "1265    False         False        False          False       False\n",
      "1266    False         False        False          False       False\n",
      "1267    False         False        False          False       False\n",
      "1268    False         False        False           True       False\n",
      "\n",
      "[1269 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "brand = pd.read_csv(\"C:/Users/vaish/Downloads/Exercises+and+Datasets2/Exercises and Datasets/Datasets/DataCo_Products.csv\")\n",
    "print(brand)\n",
    "print(brand.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cec5a167-3fd3-4ed9-b2e3-060487a752cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Prod Id  Prod Cat Id   Prod Price\n",
      "count  1269.000000  1253.000000  1254.000000\n",
      "mean    558.958235    27.213887   112.252497\n",
      "std     382.239308    20.279175   132.519540\n",
      "min      24.000000     2.000000    15.990000\n",
      "25%     365.000000    17.000000    50.000000\n",
      "50%     403.000000    18.000000    59.990002\n",
      "75%     627.000000    29.000000   129.990005\n",
      "max    1363.000000    76.000000  1500.000000\n"
     ]
    }
   ],
   "source": [
    "print(brand.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f0d6a07-f689-4f1e-a35c-c6eff9476bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prod Id           0\n",
      "Product Name     10\n",
      "Prod Cat Id      16\n",
      "Prod Cat Name     9\n",
      "Prod Price       15\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count nulls in each col\n",
    "print(brand.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74486dd3-5170-42f8-ae16-1883d9278300",
   "metadata": {},
   "source": [
    "    MANAGING DUPLICATE VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8115df7f-d368-4d24-83b7-1cb36a249de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4        True\n",
      "        ...  \n",
      "1264     True\n",
      "1265     True\n",
      "1266     True\n",
      "1267     True\n",
      "1268    False\n",
      "Length: 1269, dtype: bool\n",
      "There are total of  1177  duplicate values\n"
     ]
    }
   ],
   "source": [
    "print(brand.duplicated())\n",
    "print(\"There are total of \", brand.duplicated().sum(), \" duplicate values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c95693b-3348-4f19-86e5-ac629243ed14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1210\n",
      "1239\n",
      "1236\n",
      "1237\n",
      "1232\n"
     ]
    }
   ],
   "source": [
    "#counting number of duplicates in each col      \n",
    "print(brand[\"Prod Id\"].duplicated().sum())\n",
    "print(brand[\"Product Name\"].duplicated().sum())\n",
    "print(brand[\"Prod Cat Id\"].duplicated().sum())\n",
    "print(brand[\"Prod Cat Name\"].duplicated().sum())\n",
    "print(brand[\"Prod Price\"].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adb072a0-fee9-4ce4-8bf9-11d3c504857e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Prod Id Product Name  Prod Cat Id Prod Cat Name  Prod Price\n",
      "0         191      Nike Me          9.0    Cardio Equ   99.989998\n",
      "1         627      Under A         29.0    Shop By Sp   39.990002\n",
      "2         917      Glove I         41.0      Trade-In         NaN\n",
      "3         828      Bridges         37.0    Electronic   31.990000\n",
      "5         403      Nike Me         18.0    Men's Foot  129.990005\n",
      "...       ...          ...          ...           ...         ...\n",
      "1127      797      Hirzl W         36.0    Golf Balls   17.990000\n",
      "1189      235      Under A         11.0    Fitness Ac         NaN\n",
      "1251      135          NaN          7.0        Hockey   22.000000\n",
      "1257      135      Nike Dr          7.0        Hockey         NaN\n",
      "1268      135      Nike Dr          7.0           NaN   22.000000\n",
      "\n",
      "[92 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#Removing Duplicates\n",
    "print(brand.drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe8b6dd-ab93-4b99-a162-8c2b0ed425a7",
   "metadata": {},
   "source": [
    "    HANDLING NULL VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7804130-02af-4c68-82c3-e2ca83a537f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prod Id                                                     679721\n",
      "Product Name     Nike MeUnder ABridgesNike MeNike MeNike MeNike...\n",
      "Prod Cat Id                                                33070.0\n",
      "Prod Cat Name    Cardio EquShop By SpElectronicCardio EquMen's ...\n",
      "Prod Price                                           136596.471499\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# to drop all NULL value rows\n",
    "print(brand.dropna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4573c09-47ba-41cf-be8d-a4f7ac30ae21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Prod Id Product Name Prod Cat Id Prod Cat Name Prod Price\n",
      "1256      135      Nike Dr         7.0        Hockey       22.0\n",
      "1257      135      Nike Dr         7.0        Hockey         hi\n",
      "1258      135      Nike Dr         7.0        Hockey       22.0\n",
      "1259      135      Nike Dr         7.0        Hockey       22.0\n",
      "1260      135      Nike Dr         7.0        Hockey       22.0\n",
      "1261      135      Nike Dr         7.0        Hockey       22.0\n",
      "1262      135      Nike Dr         7.0        Hockey       22.0\n",
      "1263      135      Nike Dr         7.0        Hockey       22.0\n",
      "1264      135      Nike Dr         7.0        Hockey       22.0\n",
      "1265      135      Nike Dr         7.0        Hockey       22.0\n",
      "1266      135      Nike Dr         7.0        Hockey       22.0\n",
      "1267      135      Nike Dr         7.0        Hockey       22.0\n",
      "1268      135      Nike Dr         7.0            hi       22.0\n"
     ]
    }
   ],
   "source": [
    "# to fill NULL cells with any value\n",
    "import numpy as np\n",
    "print(brand.replace(np.nan,'hi').tail(13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08564b9d-9c71-4ee0-b0c1-db2fee67633d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Prod Id Product Name  Prod Cat Id Prod Cat Name  Prod Price\n",
      "0       191      Nike Me          9.0    Cardio Equ   99.989998\n",
      "1       627      Under A         29.0    Shop By Sp   39.990002\n",
      "2       917      Glove I         41.0      Trade-In   31.990000\n",
      "3       828      Bridges         37.0    Electronic   31.990000\n",
      "4       191      Nike Me          9.0    Cardio Equ   99.989998\n",
      "5       403      Nike Me         18.0    Men's Foot  129.990005\n",
      "6       403      Nike Me         18.0    Men's Foot  129.990005\n",
      "7       403      Nike Me         18.0    Men's Foot  129.990005\n",
      "8       365      Perfect         17.0        Cleats   59.990002\n",
      "9       403      Nike Me         18.0    Men's Foot  129.990005\n",
      "10      957      Diamond         43.0    Camping &   299.980011\n",
      "11      957      Diamond         43.0    Camping &   299.980011\n",
      "12      365      Perfect         17.0        Cleats   59.990002\n",
      "13      365      Perfect         17.0        Cleats   59.990002\n",
      "14      502      Nike Me         24.0    Women's Ap   50.000000\n",
      "15      627      Under A         29.0    Shop By Sp   39.990002\n",
      "16      502      Nike Me         24.0    Women's Ap   50.000000\n",
      "17      905      Team Go          9.0    Accessorie   24.990000\n",
      "18      191      Nike Me          9.0    Cardio Equ   99.989998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaish\\AppData\\Local\\Temp\\ipykernel_19056\\1199138802.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  print(brand.fillna(method=\"bfill\").head(19))\n"
     ]
    }
   ],
   "source": [
    "# to fill below value in NAN value cells\n",
    "\n",
    "print(brand.fillna(method=\"bfill\").head(19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8dab891-0fb3-436c-bf86-383edbd8c937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Prod Id Product Name  Prod Cat Id Prod Cat Name  Prod Price\n",
      "0       191      Nike Me          9.0    Cardio Equ   99.989998\n",
      "1       627      Under A         29.0    Shop By Sp   39.990002\n",
      "2       917      Glove I         41.0      Trade-In   39.990002\n",
      "3       828      Bridges         37.0    Electronic   31.990000\n",
      "4       191      Nike Me          9.0    Cardio Equ   99.989998\n",
      "5       403      Nike Me         18.0    Men's Foot  129.990005\n",
      "6       403      Nike Me         18.0    Men's Foot  129.990005\n",
      "7       403      Nike Me         18.0    Men's Foot  129.990005\n",
      "8       365      Perfect         17.0        Cleats   59.990002\n",
      "9       403      Nike Me         18.0    Men's Foot  129.990005\n",
      "10      957      Diamond         43.0    Camping &   299.980011\n",
      "11      957      Diamond         43.0    Camping &   299.980011\n",
      "12      365      Perfect         17.0        Cleats   59.990002\n",
      "13      365      Perfect         17.0        Cleats   59.990002\n",
      "14      502      Nike Me         24.0    Women's Ap   50.000000\n",
      "15      627      Under A         29.0    Shop By Sp   39.990002\n",
      "16      502      Nike Me         24.0    Women's Ap   50.000000\n",
      "17      905      Team Go         24.0    Accessorie   24.990000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaish\\AppData\\Local\\Temp\\ipykernel_19056\\3231360654.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  print(brand.fillna(method=\"ffill\").head(18))\n"
     ]
    }
   ],
   "source": [
    "# to fill previous value in NAN value cells\n",
    "\n",
    "print(brand.fillna(method=\"ffill\").head(18))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fe1740-47a2-4b7f-9b55-5e3dabaac6ed",
   "metadata": {},
   "source": [
    "    TRANSFORMING COLUMN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b326546f-24fe-4284-bd27-bbab384032a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EmpID First Name Last Name  Salary Joined Month\n",
      "0    E1       Ross      Trib   20000      January\n",
      "1    E2     Rachel      Bing   40000     February\n",
      "2    E7     Monica     Green   25000        March\n",
      "3    E8       Joey    Geller   60000        April\n",
      "4    E4   Chandler    Buffay   33000          May\n",
      "5    E5     Pheobe      Bing   45000         June\n",
      "\n",
      "  EmpID First Name Last Name  Salary Joined Month         Fullname    Bonus\n",
      "0    E1       Ross      Trib   20000      January        Ross Trib   4000.0\n",
      "1    E2     Rachel      Bing   40000     February      Rachel Bing   8000.0\n",
      "2    E7     Monica     Green   25000        March     Monica Green   5000.0\n",
      "3    E8       Joey    Geller   60000        April      Joey Geller  12000.0\n",
      "4    E4   Chandler    Buffay   33000          May  Chandler Buffay   6600.0\n",
      "5    E5     Pheobe      Bing   45000         June      Pheobe Bing   9000.0\n"
     ]
    }
   ],
   "source": [
    "# to read xl file & concat 2 col\n",
    "#in CMD type pip install openpyxl\n",
    "import pandas as pd\n",
    "actor = pd.read_excel(\"C:/Users/vaish/Downloads/Exercises+and+Datasets2/Exercises and Datasets/Datasets/practice.xlsx\")\n",
    "print(actor)\n",
    "print()\n",
    "actor[\"Fullname\"] = actor[\"First Name\"].str.capitalize() +\" \"+actor[\"Last Name\"].str.capitalize()\n",
    "actor[\"Bonus\"] = (actor[\"Salary\"]/100)*20\n",
    "print(actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0336b33-13d2-4adf-b81d-cbb4f29b7732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Prod Id Product Name  Prod Cat Id Prod Cat Name   Prod Price  \\\n",
      "0        191      Nike Me          9.0    Cardio Equ    99.989998   \n",
      "1        627      Under A         29.0    Shop By Sp    39.990002   \n",
      "2        917      Glove I         41.0      Trade-In          NaN   \n",
      "3        828      Bridges         37.0    Electronic    31.990000   \n",
      "4        191      Nike Me          9.0    Cardio Equ    99.989998   \n",
      "..       ...          ...          ...           ...          ...   \n",
      "295     1349      Web Cam         62.0      Cameras    452.040008   \n",
      "296     1349      Web Cam         62.0      Cameras           NaN   \n",
      "297     1351      Dell La         64.0     Computers  1500.000000   \n",
      "298     1349      Web Cam         62.0      Cameras    452.040008   \n",
      "299     1352      Industr         65.0    Consumer E   252.880005   \n",
      "\n",
      "        Price Category  \n",
      "0        cheap product  \n",
      "1        cheap product  \n",
      "2                  NaN  \n",
      "3        cheap product  \n",
      "4        cheap product  \n",
      "..                 ...  \n",
      "295     normal product  \n",
      "296                NaN  \n",
      "297  expensive product  \n",
      "298     normal product  \n",
      "299     normal product  \n",
      "\n",
      "[300 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# to add column with conditions\n",
    "brand.loc[(brand[\"Prod Price\"]<100),'Price Category'] = \"cheap product\"\n",
    "brand.loc[np.logical_and(brand[\"Prod Price\"]>=100,brand[\"Prod Price\"]<500),'Price Category'] = \"normal product\"\n",
    "brand.loc[np.logical_and(brand[\"Prod Price\"]>=500,brand[\"Prod Price\"]<1000),'Price Category'] = \"average product\"\n",
    "brand.loc[(brand[\"Prod Price\"]>1000),'Price Category'] = \"expensive product\"\n",
    "print(brand.head(300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ed6864b-a7bf-4155-8dc3-45378f5da107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EmpID First Name Last Name  Salary Joined Month         Fullname    Bonus  \\\n",
      "0    E1       Ross      Trib   20000      January        Ross Trib   4000.0   \n",
      "1    E2     Rachel      Bing   40000     February      Rachel Bing   8000.0   \n",
      "2    E7     Monica     Green   25000        March     Monica Green   5000.0   \n",
      "3    E8       Joey    Geller   60000        April      Joey Geller  12000.0   \n",
      "4    E4   Chandler    Buffay   33000          May  Chandler Buffay   6600.0   \n",
      "5    E5     Pheobe      Bing   45000         June      Pheobe Bing   9000.0   \n",
      "\n",
      "  short_month  \n",
      "0         Jan  \n",
      "1         Feb  \n",
      "2         Mar  \n",
      "3         Apr  \n",
      "4         May  \n",
      "5         Jun  \n"
     ]
    }
   ],
   "source": [
    "# extract some text from data \n",
    "\n",
    "def extract(value):\n",
    "    return value[0:3]\n",
    "\n",
    "actor[\"short_month\"] = actor[\"Joined Month\"].map(extract)\n",
    "print(actor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9d4fc1-af2a-4631-8aa1-574f5b3edb0a",
   "metadata": {},
   "source": [
    "    GROUPING & FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fd7a6c55-73b9-44c1-8051-9b424bd1959a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       EEID     Full Name        Job Title  Department  \\\n",
      "989  E04354  Raelynn Rios   Vice President       Sales   \n",
      "232  E04742  Kinsley Vega   Vice President  Accounting   \n",
      "900  E02522  Silas Rivera   Vice President       Sales   \n",
      "549  E01371    Dominic Le   Vice President   Marketing   \n",
      "610  E04170  Grayson Chin   Vice President          IT   \n",
      "..      ...           ...              ...         ...   \n",
      "787  E02732    Alice Tran          Analyst   Marketing   \n",
      "182  E03719    Jack Brown          Analyst   Marketing   \n",
      "823  E00862   Levi Moreno  Systems Analyst          IT   \n",
      "782  E04109   Leah Bryant   IT Coordinator          IT   \n",
      "781  E03928    Miles Dang   IT Coordinator          IT   \n",
      "\n",
      "              Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "989           Manufacturing  Female     Latino   43 2016-08-21         258498   \n",
      "232               Corporate  Female     Latino   33 2020-12-16         258426   \n",
      "900               Corporate    Male     Latino   48 2000-02-28         258081   \n",
      "549               Corporate    Male      Asian   41 2014-10-04         257194   \n",
      "610  Research & Development    Male      Asian   26 2020-05-09         256561   \n",
      "..                      ...     ...        ...  ...        ...            ...   \n",
      "787               Corporate  Female      Asian   39 2014-07-29          40897   \n",
      "182               Corporate    Male  Caucasian   55 2004-12-07          40752   \n",
      "823  Research & Development    Male     Latino   64 2020-06-27          40316   \n",
      "782           Manufacturing  Female  Caucasian   55 2004-04-30          40124   \n",
      "781     Speciality Products    Male      Asian   61 2000-09-24          40063   \n",
      "\n",
      "     Bonus %        Country            City Exit Date  \n",
      "989     0.35  United States        Columbus       NaT  \n",
      "232     0.40         Brazil  Rio de Janerio       NaT  \n",
      "900     0.30  United States         Chicago       NaT  \n",
      "549     0.35          China       Chongqing       NaT  \n",
      "610     0.39  United States          Austin       NaT  \n",
      "..       ...            ...             ...       ...  \n",
      "787     0.00  United States         Seattle       NaT  \n",
      "182     0.00  United States         Phoenix       NaT  \n",
      "823     0.00         Brazil          Manaus       NaT  \n",
      "782     0.00  United States          Austin       NaT  \n",
      "781     0.00  United States           Miami       NaT  \n",
      "\n",
      "[1000 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# to sort data based on increasing salary\n",
    "emp = pd.read_excel(\"ESD.xlsx\")\n",
    "print(emp.sort_values(\"Annual Salary\",ascending=False))\n",
    "#to sort based on multiple cols\n",
    "print(emp.sort_values([\"Bonus %\",\"Annual Salary]))\n",
    "#to sort asc/desc differently on different cols\n",
    "print(emp.sort_values([\"Bonus %\",\"Annual Salary\"],ascending=[True , False]))\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5247ad5e-a80b-40f0-b263-084ddcb6499c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 EEID\n",
      "Department           \n",
      "Accounting         96\n",
      "Engineering       158\n",
      "Finance           120\n",
      "Human Resources   125\n",
      "IT                241\n",
      "Marketing         120\n",
      "Sales             140\n",
      "                               EEID\n",
      "Job Title              Gender      \n",
      "Account Representative Female    15\n",
      "                       Male       6\n",
      "Analyst                Female    31\n",
      "                       Male      20\n",
      "Analyst II             Female    21\n",
      "...                             ...\n",
      "Technical Architect    Male       8\n",
      "Test Engineer          Female     7\n",
      "                       Male       5\n",
      "Vice President         Female    50\n",
      "                       Male      55\n",
      "\n",
      "[66 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# grouping above data based on any column\n",
    "gbd = emp.groupby(\"Department\").agg({\"EEID\":\"count\"})\n",
    "print(gbd)\n",
    "gbjt = emp.groupby([\"Job Title\",\"Gender\"]).agg({\"EEID\":\"count\"})\n",
    "print(gbjt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0777d6b-1bc5-4092-aa95-ffbf8dc377ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Age\n",
      "Country                 \n",
      "Brazil         43.654676\n",
      "China          45.389908\n",
      "United States  44.197512\n",
      "                            Age\n",
      "Country       Gender           \n",
      "Brazil        Female  42.240000\n",
      "              Male    45.312500\n",
      "China         Female  44.752294\n",
      "              Male    46.027523\n",
      "United States Female  44.580838\n",
      "              Male    43.783172\n"
     ]
    }
   ],
   "source": [
    "# grouping based on avg resource age of each country\n",
    "gbc = emp.groupby(\"Country\").agg({\"Age\":\"mean\"})\n",
    "print(gbc)\n",
    "gbc = emp.groupby([\"Country\",\"Gender\"]).agg({\"Age\":\"mean\"})\n",
    "print(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f938398b-b0c0-4bef-b665-75c7510f2d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Annual Salary\n",
      "Country                     \n",
      "Brazil                258426\n",
      "China                 257194\n",
      "United States         258498\n",
      "                      Annual Salary  Age\n",
      "Country       Gender                    \n",
      "Brazil        Female         258426   25\n",
      "              Male           249506   26\n",
      "China         Female         249686   25\n",
      "              Male           257194   25\n",
      "United States Female         258498   25\n",
      "              Male           258081   25\n"
     ]
    }
   ],
   "source": [
    "# grouping based on max salary of each country\n",
    "gbs = emp.groupby(\"Country\").agg({\"Annual Salary\":\"max\"})\n",
    "print(gbs)\n",
    "gbs = emp.groupby([\"Country\",\"Gender\"]).agg({\"Annual Salary\":\"max\",\"Age\":\"min\"})\n",
    "print(gbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "080a8414-4247-4f02-b886-36875675bc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          Black\n",
      "1          Asian\n",
      "2      Caucasian\n",
      "3      Caucasian\n",
      "4          Asian\n",
      "         ...    \n",
      "995    Caucasian\n",
      "996        Asian\n",
      "997        Asian\n",
      "998        Asian\n",
      "999        Asian\n",
      "Name: Ethnicity, Length: 1000, dtype: object\n",
      "     Ethnicity        Country\n",
      "0        Black  United States\n",
      "1        Asian          China\n",
      "2    Caucasian  United States\n",
      "3    Caucasian  United States\n",
      "4        Asian  United States\n",
      "..         ...            ...\n",
      "995  Caucasian  United States\n",
      "996      Asian          China\n",
      "997      Asian  United States\n",
      "998      Asian          China\n",
      "999      Asian  United States\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "       EEID          Full Name                 Job Title  Department  \\\n",
      "0    E02387        Emily Davis                Sr. Manger          IT   \n",
      "2    E02572       Luna Sanders                  Director     Finance   \n",
      "3    E02832    Penelope Jordan  Computer Systems Manager          IT   \n",
      "6    E01550        Ruby Barnes                   Manager          IT   \n",
      "8    E04533      Easton Bailey                   Manager  Accounting   \n",
      "..      ...                ...                       ...         ...   \n",
      "989  E04354       Raelynn Rios            Vice President       Sales   \n",
      "990  E01578       Anthony Hong                Sr. Manger          IT   \n",
      "993  E04762  Audrey Richardson                  Director          IT   \n",
      "997  E04398        Oliver Yang                  Director   Marketing   \n",
      "999  E03545        Sofia Cheng            Vice President  Accounting   \n",
      "\n",
      "              Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "0    Research & Development  Female      Black   55 2016-04-08         141604   \n",
      "2       Speciality Products  Female  Caucasian   50 2006-10-26         163099   \n",
      "3             Manufacturing  Female  Caucasian   26 2019-09-27          84913   \n",
      "6                 Corporate  Female  Caucasian   27 2020-07-01         119746   \n",
      "8             Manufacturing    Male  Caucasian   29 2019-01-25         113527   \n",
      "..                      ...     ...        ...  ...        ...            ...   \n",
      "989           Manufacturing  Female     Latino   43 2016-08-21         258498   \n",
      "990  Research & Development    Male      Asian   37 2010-11-29         146961   \n",
      "993           Manufacturing  Female  Caucasian   46 2018-10-06         166259   \n",
      "997     Speciality Products    Male      Asian   31 2019-06-10         176710   \n",
      "999               Corporate  Female      Asian   63 2020-07-26         216195   \n",
      "\n",
      "     Bonus %        Country      City  Exit Date  \n",
      "0       0.15  United States   Seattle 2021-10-16  \n",
      "2       0.20  United States   Chicago        NaT  \n",
      "3       0.07  United States   Chicago        NaT  \n",
      "6       0.10  United States   Phoenix        NaT  \n",
      "8       0.06  United States    Austin        NaT  \n",
      "..       ...            ...       ...        ...  \n",
      "989     0.35  United States  Columbus        NaT  \n",
      "990     0.11  United States  Columbus        NaT  \n",
      "993     0.17  United States   Chicago        NaT  \n",
      "997     0.15  United States     Miami        NaT  \n",
      "999     0.31  United States     Miami        NaT  \n",
      "\n",
      "[475 rows x 14 columns]\n",
      "       EEID       Full Name               Job Title   Department  \\\n",
      "11   E03344   Camila Rogers       Controls Engineer  Engineering   \n",
      "13   E04239    Everleigh Ng              Sr. Manger      Finance   \n",
      "21   E04732      Eva Rivera                Director        Sales   \n",
      "51   E00415  Leilani Butler              Analyst II    Marketing   \n",
      "52   E02862    Peyton Huang              Sr. Manger           IT   \n",
      "..      ...             ...                     ...          ...   \n",
      "937  E02696         Ryan Lu    Development Engineer  Engineering   \n",
      "952  E03000     Hailey Hong  Account Representative        Sales   \n",
      "959  E01488      Stella Lai             Sr. Analyst   Accounting   \n",
      "980  E00785    Hannah Hoang                 Manager   Accounting   \n",
      "984  E02191       Maria Sun                Director        Sales   \n",
      "\n",
      "              Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "11      Speciality Products  Female  Caucasian   27 2021-10-21         109851   \n",
      "13   Research & Development  Female      Asian   51 2021-06-10         146742   \n",
      "21            Manufacturing  Female     Latino   36 2021-04-02         151703   \n",
      "51            Manufacturing  Female      Black   27 2021-09-21          68728   \n",
      "52            Manufacturing  Female      Asian   25 2021-07-02         125633   \n",
      "..                      ...     ...        ...  ...        ...            ...   \n",
      "937     Speciality Products    Male      Asian   25 2021-07-08          67275   \n",
      "952  Research & Development  Female      Asian   33 2021-01-22          56405   \n",
      "959           Manufacturing  Female      Asian   44 2021-04-28          98520   \n",
      "980     Speciality Products  Female      Asian   25 2021-12-15         114893   \n",
      "984               Corporate  Female      Asian   25 2021-12-19         150666   \n",
      "\n",
      "     Bonus %        Country      City Exit Date  \n",
      "11      0.00  United States   Seattle       NaT  \n",
      "13      0.10          China  Shanghai       NaT  \n",
      "21      0.21  United States     Miami       NaT  \n",
      "51      0.00  United States   Phoenix       NaT  \n",
      "52      0.11          China   Beijing       NaT  \n",
      "..       ...            ...       ...       ...  \n",
      "937     0.00  United States  Columbus       NaT  \n",
      "952     0.00  United States   Chicago       NaT  \n",
      "959     0.00  United States     Miami       NaT  \n",
      "980     0.06          China   Chengdu       NaT  \n",
      "984     0.23          China   Chengdu       NaT  \n",
      "\n",
      "[86 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "#filtering data based on particular column(s)\n",
    "print(emp[\"Ethnicity\"])\n",
    "print(emp[[\"Ethnicity\",\"Country\"]])\n",
    "print(emp[emp[\"Bonus %\"]>0])\n",
    "print(emp[emp[\"Hire Date\"]>\"2021-01-01\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fe844619-0efc-4e71-8233-668bfa283296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       EEID       Full Name                       Job Title Department  \\\n",
      "1    E04105   Theodore Dinh             Technical Architect         IT   \n",
      "29   E00304      Dylan Choi                  Vice President         IT   \n",
      "30   E02594   Ezekiel Kumar                  IT Coordinator         IT   \n",
      "52   E02862    Peyton Huang                      Sr. Manger         IT   \n",
      "69   E03349      Anna Mehta  Cloud Infrastructure Architect         IT   \n",
      "..      ...             ...                             ...        ...   \n",
      "953  E01611   Gabriella Zhu        Computer Systems Manager         IT   \n",
      "956  E03168         Nora Le                      Sr. Manger         IT   \n",
      "982  E03247     Aaliyah Mai                  Vice President         IT   \n",
      "990  E01578    Anthony Hong                      Sr. Manger         IT   \n",
      "994  E01148  Scarlett Kumar                 Systems Analyst         IT   \n",
      "\n",
      "              Business Unit  Gender Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "1             Manufacturing    Male     Asian   59 1997-11-29          99975   \n",
      "29                Corporate    Male     Asian   63 2012-05-11         231141   \n",
      "30   Research & Development    Male     Asian   28 2017-06-25          54775   \n",
      "52            Manufacturing  Female     Asian   25 2021-07-02         125633   \n",
      "69      Speciality Products  Female     Asian   32 2020-01-05          78844   \n",
      "..                      ...     ...       ...  ...        ...            ...   \n",
      "953     Speciality Products  Female     Asian   36 2014-11-29          88730   \n",
      "956           Manufacturing  Female     Asian   53 1997-04-12         154388   \n",
      "982     Speciality Products  Female     Asian   57 2016-11-11         246589   \n",
      "990  Research & Development    Male     Asian   37 2010-11-29         146961   \n",
      "994               Corporate  Female     Asian   55 2009-01-07          47032   \n",
      "\n",
      "     Bonus %        Country       City  Exit Date  \n",
      "1       0.00          China  Chongqing        NaT  \n",
      "29      0.34          China    Beijing        NaT  \n",
      "30      0.00  United States   Columbus        NaT  \n",
      "52      0.11          China    Beijing        NaT  \n",
      "69      0.00  United States    Seattle        NaT  \n",
      "..       ...            ...        ...        ...  \n",
      "953     0.08          China  Chongqing        NaT  \n",
      "956     0.10  United States    Seattle        NaT  \n",
      "982     0.33  United States    Phoenix 2017-03-26  \n",
      "990     0.11  United States   Columbus        NaT  \n",
      "994     0.00  United States   Columbus        NaT  \n",
      "\n",
      "[93 rows x 14 columns]\n",
      "\n",
      "       EEID           Full Name                   Job Title       Department  \\\n",
      "79   E02166           John Soto                  Sr. Manger          Finance   \n",
      "117  E04379  Scarlett Rodriguez                 Sr. Analyst          Finance   \n",
      "339  E00265        Mila Vasquez            Quality Engineer      Engineering   \n",
      "363  E04571    Hadley Contreras                    Director      Engineering   \n",
      "372  E03854           Camila Li                  Sr. Manger               IT   \n",
      "482  E02185         Aubrey Yoon        Sr. Business Partner  Human Resources   \n",
      "485  E00784         Ella Nguyen        Service Desk Analyst               IT   \n",
      "491  E00436       Lincoln Reyes    Computer Systems Manager               IT   \n",
      "493  E04662        Julia Morris                  Sr. Manger  Human Resources   \n",
      "540  E03181        Greyson Dang        Development Engineer      Engineering   \n",
      "566  E03402           Isaac Liu              Field Engineer      Engineering   \n",
      "572  E00161             Ryan Ha              Vice President        Marketing   \n",
      "585  E04087           Adam Kaur                     Manager               IT   \n",
      "633  E04277              Zoe Do                  Analyst II            Sales   \n",
      "664  E02884        Axel Johnson                    Director  Human Resources   \n",
      "673  E04221          Roman King                  Analyst II          Finance   \n",
      "688  E03968         Joshua Chin                  Sr. Manger        Marketing   \n",
      "755  E04415       Penelope Fong                    Director       Accounting   \n",
      "780  E01413     Caroline Nelson  Sr. Account Representative            Sales   \n",
      "797  E00287         Luca Nelson                     Manager          Finance   \n",
      "868  E04464         Cooper Yoon         Engineering Manager      Engineering   \n",
      "986  E03349          Dylan Chin                    Director          Finance   \n",
      "\n",
      "              Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "79            Manufacturing    Male     Latino   60 2015-09-23         141899   \n",
      "117           Manufacturing  Female     Latino   60 2007-02-24          71699   \n",
      "339           Manufacturing  Female     Latino   60 1998-07-16          92932   \n",
      "363               Corporate  Female     Latino   60 2017-01-04         178502   \n",
      "372  Research & Development  Female      Asian   60 2010-07-24         126911   \n",
      "482  Research & Development  Female      Asian   60 2005-11-11          78388   \n",
      "485               Corporate  Female      Asian   60 2004-02-10          90258   \n",
      "491           Manufacturing    Male     Latino   60 1998-08-03          85120   \n",
      "493               Corporate  Female  Caucasian   60 2008-10-18         150855   \n",
      "540           Manufacturing    Male      Asian   60 2009-05-11          62239   \n",
      "566           Manufacturing    Male      Asian   60 1992-10-13          88213   \n",
      "572               Corporate    Male      Asian   60 2007-01-27         234311   \n",
      "585               Corporate    Male      Asian   60 2000-01-29         109059   \n",
      "633     Speciality Products  Female      Asian   60 2014-01-08          51877   \n",
      "664               Corporate    Male  Caucasian   60 2015-04-14         155788   \n",
      "673               Corporate    Male  Caucasian   60 2007-08-16          58671   \n",
      "688           Manufacturing    Male      Asian   60 2021-07-26         121480   \n",
      "755               Corporate  Female      Asian   60 2004-05-14         186378   \n",
      "780     Speciality Products  Female      Black   60 1997-07-30          71677   \n",
      "797     Speciality Products    Male  Caucasian   60 2010-06-15         106578   \n",
      "868  Research & Development    Male      Asian   60 2018-02-15         106079   \n",
      "986               Corporate    Male      Asian   60 2017-06-05         158898   \n",
      "\n",
      "     Bonus %        Country       City  Exit Date  \n",
      "79      0.15  United States    Phoenix        NaT  \n",
      "117     0.00         Brazil     Manaus        NaT  \n",
      "339     0.00  United States   Columbus        NaT  \n",
      "363     0.20  United States     Austin        NaT  \n",
      "372     0.10          China   Shanghai        NaT  \n",
      "482     0.00          China  Chongqing        NaT  \n",
      "485     0.00          China  Chongqing        NaT  \n",
      "491     0.09  United States    Seattle        NaT  \n",
      "493     0.11  United States    Phoenix        NaT  \n",
      "540     0.00          China    Beijing        NaT  \n",
      "566     0.00          China  Chongqing        NaT  \n",
      "572     0.37  United States      Miami        NaT  \n",
      "585     0.07          China    Chengdu        NaT  \n",
      "633     0.00          China    Beijing        NaT  \n",
      "664     0.17  United States    Seattle        NaT  \n",
      "673     0.00  United States   Columbus        NaT  \n",
      "688     0.14  United States    Phoenix        NaT  \n",
      "755     0.26          China  Chongqing        NaT  \n",
      "780     0.00  United States   Columbus        NaT  \n",
      "797     0.09  United States      Miami        NaT  \n",
      "868     0.14  United States     Austin 2021-04-09  \n",
      "986     0.18  United States      Miami        NaT  \n"
     ]
    }
   ],
   "source": [
    "#subsetting based on multiple conditions\n",
    "is_asian = emp[\"Ethnicity\"] == \"Asian\"\n",
    "is_IT = emp[\"Department\"] == \"IT\"\n",
    "print(emp[is_asian & is_IT])\n",
    "print()\n",
    "is_age = emp[\"Age\"].isin([10,20,60,70,80,90])\n",
    "print(emp[is_age])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73caa18-f4fa-44b6-8852-642b450da938",
   "metadata": {},
   "source": [
    "    MERGE DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "959e7725-551f-4b3a-80cf-6286e7311775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EmpID   Names Age\n",
      "0   E01     Ram  34\n",
      "1   E02   Shyam  56\n",
      "2   E03   Rahul  23\n",
      "3   E04  Vishal  44\n",
      "4   E05    Ravi  32\n",
      "5   E06    John  55 \n",
      "   EmpID Salary\n",
      "0   E01  34000\n",
      "1   E02  56000\n",
      "2   E03  23000\n",
      "3   E04  44000\n",
      "4   E05  32000\n",
      "5   E06  55000\n",
      "  EmpID   Names Age Salary\n",
      "0   E01     Ram  34  34000\n",
      "1   E02   Shyam  56  56000\n",
      "2   E03   Rahul  23  23000\n",
      "3   E04  Vishal  44  44000\n",
      "4   E05    Ravi  32  32000\n",
      "5   E06    John  55  55000\n"
     ]
    }
   ],
   "source": [
    "dayta1 = {\"EmpID\":[\"E01\",\"E02\",\"E03\",\"E04\",\"E05\",\"E06\"],\n",
    "       \"Names\":[\"Ram\",\"Shyam\",\"Rahul\",\"Vishal\",\"Ravi\",\"John\"],\n",
    "       \"Age\":[\"34\",\"56\",\"23\",\"44\",\"32\",\"55\"]}\n",
    "dayta2 = {\"EmpID\":[\"E01\",\"E02\",\"E03\",\"E04\",\"E05\",\"E06\"],\n",
    "       \"Salary\":[\"34000\",\"56000\",\"23000\",\"44000\",\"32000\",\"55000\"]}\n",
    "df1 = pd.DataFrame(dayta1)\n",
    "df2 = pd.DataFrame(dayta2)\n",
    "print(df1,\"\\n\",df2)\n",
    "print(pd.merge(df1,df2,on=\"EmpID\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c36bf740-9efb-470e-ad9f-bffa7c5a75bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EmpID   Names Age\n",
      "0   E01     Ram  34\n",
      "1   E02   Shyam  56\n",
      "2   E03   Rahul  23\n",
      "3   E04  Vishal  44\n",
      "4   E05    Ravi  32\n",
      "5   E06    John  55 \n",
      "   EmpID Salary\n",
      "0   E01  34000\n",
      "1   E07  56000\n",
      "2   E03  23000\n",
      "3   E04  44000\n",
      "4   E08  32000\n",
      "5   E06  55000\n",
      "  EmpID   Names Age Salary\n",
      "0   E01     Ram  34  34000\n",
      "1   E03   Rahul  23  23000\n",
      "2   E04  Vishal  44  44000\n",
      "3   E06    John  55  55000\n"
     ]
    }
   ],
   "source": [
    "data1 = {\"EmpID\":[\"E01\",\"E02\",\"E03\",\"E04\",\"E05\",\"E06\"],\n",
    "       \"Names\":[\"Ram\",\"Shyam\",\"Rahul\",\"Vishal\",\"Ravi\",\"John\"],\n",
    "       \"Age\":[\"34\",\"56\",\"23\",\"44\",\"32\",\"55\"]}\n",
    "data2 = {\"EmpID\":[\"E01\",\"E07\",\"E03\",\"E04\",\"E08\",\"E06\"],\n",
    "       \"Salary\":[\"34000\",\"56000\",\"23000\",\"44000\",\"32000\",\"55000\"]}\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n",
    "print(df1,\"\\n\",df2)\n",
    "print(pd.merge(df1,df2,on=\"EmpID\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46c0ce57-5119-4159-81e1-7ac07262f164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EmpID   Names Age Salary\n",
      "0   E01     Ram  34  34000\n",
      "1   E03   Rahul  23  23000\n",
      "2   E04  Vishal  44  44000\n",
      "3   E06    John  55  55000 \n",
      "\n",
      "  EmpID   Names Age Salary\n",
      "0   E01     Ram  34  34000\n",
      "1   E02   Shyam  56    NaN\n",
      "2   E03   Rahul  23  23000\n",
      "3   E04  Vishal  44  44000\n",
      "4   E05    Ravi  32    NaN\n",
      "5   E06    John  55  55000 \n",
      "\n",
      "  EmpID   Names  Age Salary\n",
      "0   E01     Ram   34  34000\n",
      "1   E07     NaN  NaN  56000\n",
      "2   E03   Rahul   23  23000\n",
      "3   E04  Vishal   44  44000\n",
      "4   E08     NaN  NaN  32000\n",
      "5   E06    John   55  55000\n"
     ]
    }
   ],
   "source": [
    "#merging if table values are different\n",
    "print(pd.merge(df1,df2,on=\"EmpID\",how=\"inner\"),\"\\n\")\n",
    "print(pd.merge(df1,df2,on=\"EmpID\",how=\"left\"),\"\\n\")\n",
    "print(pd.merge(df1,df2,on=\"EmpID\",how=\"right\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b680c2b3-2ccc-455a-a725-b4c0d03404ff",
   "metadata": {},
   "source": [
    "    CONCATENATE DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "459006ae-23c6-4096-8c8f-b60c353441ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EmpID   Names Age\n",
      "0   E01     Ram  34\n",
      "1   E02   Shyam  56\n",
      "2   E03   Rahul  23\n",
      "3   E04  Vishal  44\n",
      "4   E05    Ravi  32\n",
      "0   E06   cintu  10\n",
      "1   E07   bittu   5\n",
      "2   E08   pappu  17\n",
      "3   E09   chotu  11\n",
      "4   E10    golu   8\n"
     ]
    }
   ],
   "source": [
    "da1 = {\"EmpID\":[\"E01\",\"E02\",\"E03\",\"E04\",\"E05\"],\n",
    "       \"Names\":[\"Ram\",\"Shyam\",\"Rahul\",\"Vishal\",\"Ravi\"],\n",
    "       \"Age\":[\"34\",\"56\",\"23\",\"44\",\"32\"]}\n",
    "da2 = {\"EmpID\":[\"E06\",\"E07\",\"E08\",\"E09\",\"E10\"],\n",
    "       \"Names\":[\"cintu\",\"bittu\",\"pappu\",\"chotu\",\"golu\"],\n",
    "       \"Age\":[\"10\",\"5\",\"17\",\"11\",\"8\"]}\n",
    "dat1 = pd.DataFrame(da1)\n",
    "dat2 = pd.DataFrame(da2)\n",
    "print(pd.concat([dat1,dat2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cf0cac-f918-4f8d-9a5f-5c6520f1c9b7",
   "metadata": {},
   "source": [
    "    COMPARING DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "84c5ea06-b6e1-4db6-9244-235ab27b2040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Fruits Price Quantity\n",
      "0   apple   100       15\n",
      "1   mango   150       10\n",
      "2  banana    50       10\n",
      "3  papaya    35        3 \n",
      "\n",
      "   Fruits Price Quantity\n",
      "0   apple   120       12\n",
      "1   mango   175       15\n",
      "2  banana    50       10\n",
      "3  papaya    30        4\n"
     ]
    }
   ],
   "source": [
    "dict1 = {\"Fruits\":[\"apple\",\"mango\",\"banana\",\"papaya\"],\n",
    "        \"Price\":[\"100\",\"150\",\"50\",\"35\"],\n",
    "        \"Quantity\":[\"15\",\"10\",\"10\",\"3\"]}\n",
    "shopnow = pd.DataFrame(dict1)\n",
    "print(shopnow,\"\\n\")\n",
    "dict2 = dict1.copy()\n",
    "shoplater = pd.DataFrame(dict2)\n",
    "shoplater.loc[0,\"Price\"]=120\n",
    "shoplater.loc[1,\"Price\"]=175\n",
    "shoplater.loc[3,\"Price\"]=30\n",
    "shoplater.loc[0,\"Quantity\"]=12\n",
    "shoplater.loc[1,\"Quantity\"]=15\n",
    "shoplater.loc[3,\"Quantity\"]=4\n",
    "print(shoplater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6e140650-c457-454d-9eba-7ae0498a9ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Price       Quantity      \n",
      "   self other     self other\n",
      "0   100   120       15    12\n",
      "1   150   175       10    15\n",
      "3    35    30        3     4\n"
     ]
    }
   ],
   "source": [
    "print(shopnow.compare(shoplater))\n",
    "#print(shopnow.compare(shoplater, align_axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0d5e7641-fa97-4447-9bfa-8f09e9b474b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Price Quantity\n",
      "0 self    100       15\n",
      "  other   120       12\n",
      "1 self    150       10\n",
      "  other   175       15\n",
      "3 self     35        3\n",
      "  other    30        4\n"
     ]
    }
   ],
   "source": [
    "print(shopnow.compare(shoplater, align_axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "62b8fa35-4f88-489f-96a5-661594c62e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fruits       Price       Quantity      \n",
      "    self other  self other     self other\n",
      "0    NaN   NaN   100   120       15    12\n",
      "1    NaN   NaN   150   175       10    15\n",
      "2    NaN   NaN   NaN   NaN      NaN   NaN\n",
      "3    NaN   NaN    35    30        3     4\n"
     ]
    }
   ],
   "source": [
    "# to compare by keeping same values visible\n",
    "print(shopnow.compare(shoplater, keep_shape=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafed8e2-63d0-41b1-ae8f-0407bbdc3660",
   "metadata": {},
   "source": [
    "    PIVOTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "647d098d-1f41-4301-b2b9-eec6ecac6059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key   name  house\n",
      "0  k1   John    red\n",
      "1  k2    Ben   blue\n",
      "2  k1  David  green\n",
      "3  k2  Peter    red \n",
      "\n",
      "name   Ben  David John Peter\n",
      "key                         \n",
      "k1     NaN  green  red   NaN\n",
      "k2    blue    NaN  NaN   red\n"
     ]
    }
   ],
   "source": [
    "# to convert a vertical table into horizontal\n",
    "# takes parameters Index , Columns , Values\n",
    "deta = {\"key\":[\"k1\",\"k2\",\"k1\",\"k2\"],\n",
    "        \"name\":[\"John\",\"Ben\",\"David\",\"Peter\"],\n",
    "        \"house\":[\"red\",\"blue\",\"green\",\"red\"]}\n",
    "pivtbl = pd.DataFrame(deta)\n",
    "print(pivtbl,\"\\n\")\n",
    "print(pivtbl.pivot(index=\"key\",columns=\"name\",values=\"house\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bf838f8a-ad60-46cc-9e8f-f0cfb5745da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key   name  house grade\n",
      "0  k1   John    red   3rd\n",
      "1  k2    Ben   blue   8th\n",
      "2  k1  David  green   9th\n",
      "3  k2  Peter    red   8th \n",
      "\n",
      "     house                   grade                 \n",
      "name   Ben  David John Peter   Ben David John Peter\n",
      "key                                                \n",
      "k1     NaN  green  red   NaN   NaN   9th  3rd   NaN\n",
      "k2    blue    NaN  NaN   red   8th   NaN  NaN   8th\n"
     ]
    }
   ],
   "source": [
    "deta = {\"key\":[\"k1\",\"k2\",\"k1\",\"k2\"],\n",
    "        \"name\":[\"John\",\"Ben\",\"David\",\"Peter\"],\n",
    "        \"house\":[\"red\",\"blue\",\"green\",\"red\"],\n",
    "        \"grade\":[\"3rd\",\"8th\",\"9th\",\"8th\"]}\n",
    "pivtbl = pd.DataFrame(deta)\n",
    "print(pivtbl,\"\\n\")\n",
    "print(pivtbl.pivot(index=\"key\",columns=\"name\",values=[\"house\",\"grade\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab515df9-ccde-46a1-869e-ea0299916a97",
   "metadata": {},
   "source": [
    "    MELTING DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "28c52c7b-89d9-47f1-8c08-23d591805725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name  house grade\n",
      "0   John    red   3rd\n",
      "1    Ben   blue   8th\n",
      "2  David  green   9th\n",
      "3  Peter    red   8th\n"
     ]
    }
   ],
   "source": [
    "nhg = {\"name\":[\"John\",\"Ben\",\"David\",\"Peter\"],\n",
    "       \"house\":[\"red\",\"blue\",\"green\",\"red\"],\n",
    "       \"grade\":[\"3rd\",\"8th\",\"9th\",\"8th\"]}\n",
    "mlt = pd.DataFrame(nhg)\n",
    "print(mlt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "543dd2b0-5576-428b-bd2e-435dd2e99726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name variable  value\n",
      "0   John    house    red\n",
      "1    Ben    house   blue\n",
      "2  David    house  green\n",
      "3  Peter    house    red\n"
     ]
    }
   ],
   "source": [
    "#melting on house column\n",
    "print(pd.melt(mlt,id_vars=[\"name\"],value_vars=[\"house\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a3f6b133-cdc0-43a6-a92a-4cad03feea35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name variable value\n",
      "0   John    grade   3rd\n",
      "1    Ben    grade   8th\n",
      "2  David    grade   9th\n",
      "3  Peter    grade   8th\n"
     ]
    }
   ],
   "source": [
    "#melting on grade column\n",
    "print(pd.melt(mlt,id_vars=[\"name\"],value_vars=[\"grade\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1d137e00-3cd1-4a9b-8d30-ede8b6ba1a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name House&Grade   Vals\n",
      "0   John       house    red\n",
      "1    Ben       house   blue\n",
      "2  David       house  green\n",
      "3  Peter       house    red\n",
      "4   John       grade    3rd\n",
      "5    Ben       grade    8th\n",
      "6  David       grade    9th\n",
      "7  Peter       grade    8th\n"
     ]
    }
   ],
   "source": [
    "#melting on both house & grade column with renaming\n",
    "print(pd.melt(mlt,id_vars=[\"name\"],value_vars=[\"house\",\"grade\"],var_name=\"House&Grade\",value_name=\"Vals\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
